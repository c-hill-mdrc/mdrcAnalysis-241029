---
title: "hetreg_extract: Heteroskedasticity-robust Regression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{hetreg_extract: Heteroskedasticity-robust Regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mdrcAnalysis)
library(dplyr)

# load data set
data("bif_final")

# Convert COHORT to a factor for analysis
finalBif <- bif_final %>%
  dplyr::mutate(CohortFactor = factor(COHORT))
```

## Overview and Motivation

`hetreg_extract()` allows users to run impact estimations with heteroskedasticity-robust standard errors for multiple outcome variables with the same set of treatment and covariates. This function performs very similarly to the `lm_extract()` with the exception of reporting heteroskedasticity-robust standard errors. 

### What is Heteroskedasticity?
Heteroskedasticity is when the variance in a measure (outcome) is not consistent. This is rather hard or complicated to describe but is very easily demonstrated with a visual. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
mtcars2 <- mtcars |> dplyr::filter(wt < 5)

ggplot2::ggplot(mtcars2, ggplot2::aes(x=wt, y=hp)) + 
     ggplot2::geom_point() +
     ggplot2::geom_smooth(method=lm, se=FALSE) +
     ggplot2::xlab("X") +
     ggplot2::ylab("Y")
```

In this example, as `X` increases, the points get increasingly farther from the line. The errors (distance from the line) for values of `X` below 2.75 are significantly smaller than the errors for values greater than 2.75. Thus, this graph demonstrates heteroskedasticity.

### Accounting for Heteroskedasticity
One assumption of linear regression is homoscedasticity or consistent errors, thus the presence of heteroskedasticity is problematic. As a result, many efforts have been made to create adjustments that account for heteroskedasticity. There are many of these adjustments, at least 9 of which are supported by the `sandwich::vcovHC()` function which is used in `mdrcAnalysis`. A full list as well as a bit more information can be found in the [`sandwich` documentation](https://sandwich.r-forge.r-project.org/reference/vcovHC.html). This list is also provided in the `hetreg_extract()` documentation. The default is HC3. 

Largely, it is recommended to use `hetreg_extract()` and heteroskedasticity-robust standard errors when performing regression unless there is an explicit reason not to. In general, if no heteroskedasticity is present, the results will be equivalent to an `lm()` without a heteroskedasticity adjustment. However, if there is heteroskedasticity in the data, adjusting the standard errors is more accurate. 

The principle reasons to avoid heteroskedasticity adjustments is small sample sizes. The `hetreg_extract()` function will produce a message if the sample size is small enough to warrant consideration from an impact analyst. 

## Required Arguments

`hetreg_extract` requires 4 arguments (below) and has many other optional arguments:

- `.dataset=` - the study data set 
- `.dependents=` - the list of dependent/outcome variables
- `.treatment=` - the treatment variable 
- `.covariates=` - the control variables 

### BIF data

The Baseline Information Form (BIF) is a survey with a series of questions about a study participant (for example, it includes questions about their gender, date of birth, etc.). Soon after completing the BIF, study participants were randomly assigned to a program or control group. Baseline data was collected for two cohorts and provided to the data team using various file types. These synthetic BIF data are used as part of the Shoot for the Star project in the Introduction to R and Introduction to SAS trainings. 

We are using the BIF data set here to demonstrate **hetreg_extract**.

```{r}
head(finalBif)
```

### Example with BIF data

In our example below, we are using baseline characteristics from the simulated randomized control trial data as outcome variables. As it is an RCT study, we do not expect to see any *impact* differences 
between treatment and control groups based on the baseline characteristics. If we do see a difference,
it would imply that randomization may have been biased!

```{r, warning = FALSE, message = FALSE}
# Create vector of dependent variables
## Using `setdiff()` to create vector of all variables except those listed
finalBif_dependents <- names(finalBif[setdiff(names(finalBif), 
                                              c("SAMPLEID", 
                                                "RA_CODE", 
                                                "CohortFactor", 
                                                "COHORT", 
                                                "RA_DATE", 
                                                "AGE", 
                                                "DOB", 
                                                "blcurhrs_73plus"))])
finalBif_treatment  <- "RA_CODE"
finalBif_covariates <- c("CohortFactor", "AGE")

extract_r <- 
  hetreg_extract(
  .dataset = finalBif
  ,.dependents = finalBif_dependents
  ,.treatment= finalBif_treatment
  ,.covariates = finalBif_covariates
  ,.confintalpha = .9                
   #,.output_path = "/data/share/xproject/practice/user"
   #,.output_file = "hetreg_extract_example"
  ) # confidence interval - p value is .1 here.
```

As you can see in the results below for the BIF data, we have
most of all the individual level characteristics as __dependent__ variables.
As mentioned above, we are not expecting any significant differences between the control group and  program group.
You can derive that from __estimate_c__ , __estimate_p__, __impact__ and __p_value__.

If you scroll to the right, you also check for __unadj_estimate_c__ and __unadj_estimate_p__
where we see very little different. The __unadj__ estimates are not accounting for any control variables as we run
the analysis. Therefore, this is akin to checking if we have the same proportions of each variable in each
group.

```{r}
tail(extract_r)
```

